{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# add path\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "sys.path.append(r\"C:\\Users\\goelm\\OneDrive\\Desktop\\mawps\")\n",
    "\n",
    "path = r\"C:\\Users\\goelm\\OneDrive\\Desktop\\mawps\"\n",
    "\n",
    "dataloader = pickle.load(open(path + '\\mawps-dataloader.pkl', 'rb'))\n",
    "# model = pickle.load(open(path + '\\mawps-model.pkl', 'rb'))\n",
    "dataset = pickle.load(open(path + '\\mawps-dataset.pkl', 'rb'))\n",
    "trainer = pickle.load(open(path + '\\mawps-model-trainer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# model = torch.load(r\"C:\\Users\\goelm\\OneDrive\\Desktop\\model.pth\", map_location=torch.device('cuda'))\n",
    "# model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from backend.comparator_tree import *\n",
    "\n",
    "df = pd.read_pickle('backend/data/TextData/all_df.pkl')\n",
    "\n",
    "tree = df['tree']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.8 s\n",
      "Wall time: 1.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = [\n",
    "            {'sQuestion': 'the sum of 2 and a number is 1 . find the number .'\n",
    "                , 'lEquations': ['37*8=x'],\n",
    "             'iIndex': '122', 'lSolutions': ['4'], 'template': ''}\n",
    "            # {'sQuestion': \"Martin strolled to Lawrence's house. It is 12 miles from Martin's house to Lawrence's house. It took Martin 6 hours to get there. How fast did Martin go?\"\n",
    "            #     , 'lEquations': ['37*8=x'],\n",
    "            #  'iIndex': '122', 'lSolutions': ['4'], 'template': ''}\n",
    "        ]\n",
    "res = dataset.preprocesss(data, use_gpu=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "res_new = dataloader.build_batch_for_predict(res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['-', '2.0', '1.0']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goelm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\rnn.py:953: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:968.)\n",
      "  result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n"
     ]
    }
   ],
   "source": [
    "eqn = trainer.model.predict(res_new)[3][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def from_prefix_to_infix(expression):\n",
    "    r\"\"\"convert prefix equation to infix equation\n",
    "\n",
    "    Args:\n",
    "        expression (list): prefix expression.\n",
    "\n",
    "    Returns:\n",
    "        (list): infix expression.\n",
    "    \"\"\"\n",
    "    st = list()\n",
    "    last_op = []\n",
    "    priority = {\"<BRG>\": 0, \"=\": 1, \"+\": 2, \"-\": 2, \"*\": 3, \"/\": 3, \"^\": 4}\n",
    "    expression.reverse()\n",
    "    for symbol in expression:\n",
    "        if symbol not in ['+', '-', '*', '/', '^', \"=\", \"<BRG>\"]:\n",
    "            st.append([symbol])\n",
    "        else:\n",
    "            n_left = st.pop()\n",
    "            n_right = st.pop()\n",
    "            left_first = False\n",
    "            right_first = False\n",
    "            if len(n_left) > 1 and priority[last_op.pop()] < priority[symbol]:\n",
    "                left_first = True\n",
    "            if len(n_right) > 1 and priority[last_op.pop()] <= priority[symbol]:\n",
    "                right_first = True\n",
    "            if left_first:\n",
    "                n_left = ['('] + n_left + [')']\n",
    "            if right_first:\n",
    "                n_right = ['('] + n_right + [')']\n",
    "            st.append(n_left + [symbol] + n_right)\n",
    "            last_op.append(symbol)\n",
    "    res = st.pop()\n",
    "    return res\n",
    "\n",
    "def get_eqn(ques):\n",
    "    data = [\n",
    "            {'sQuestion': ques\n",
    "                , 'lEquations': ['37*8=x'],\n",
    "             'iIndex': '122', 'lSolutions': ['4'], 'template': ''}\n",
    "            # {'sQuestion': \"Martin strolled to Lawrence's house. It is 12 miles from Martin's house to Lawrence's house. It took Martin 6 hours to get there. How fast did Martin go?\"\n",
    "            #     , 'lEquations': ['37*8=x'],\n",
    "            #  'iIndex': '122', 'lSolutions': ['4'], 'template': ''}\n",
    "        ]\n",
    "    res = dataset.preprocesss(data, use_gpu=False)\n",
    "    res_new = dataloader.build_batch_for_predict(res)\n",
    "    eqn = trainer.model.predict(res_new)[3][0]\n",
    "    eqn = from_prefix_to_infix(eqn)\n",
    "    eqn = 'x = '+' '.join(eqn)\n",
    "    return eqn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import backend.graph as graph\n",
    "from backend.comparator_tree import *\n",
    "\n",
    "def get_ans_list(ques):\n",
    "    eqn = get_eqn(ques)\n",
    "    eqn_parsed = graph.eq_parser(eqn)\n",
    "    tmp = []\n",
    "    for j in range(len(tree)):\n",
    "        if len(tree[j]) == 0:\n",
    "            continue\n",
    "        if compare_tree(eqn_parsed[0], tree[j][0]) and compare_tree(eqn_parsed[1], tree[j][1]):\n",
    "            tmp.append(j)\n",
    "    return tmp, eqn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001B[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001B[0m\n",
      "\u001B[2m   Use a production WSGI server instead.\u001B[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on all addresses.\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      " * Running on http://192.168.50.170:8000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sum of 23 and a number is 1 . find the number .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goelm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\rnn.py:953: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:968.)\n",
      "  result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "192.168.50.170 - - [16/Apr/2023 02:01:50] \"POST /solve HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['-', '23.0', '1.0']]\n",
      "( x  ) (  23.0 - 1.0 )\n",
      "ram has 3 apples, shyam has 4 apples. How many they have in total?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.50.170 - - [16/Apr/2023 02:02:25] \"POST /solve HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['+', '3.0', '4.0']]\n",
      "( x  ) (  3.0 + 4.0 )\n",
      "What is 4 times 5?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192.168.50.170 - - [16/Apr/2023 02:02:49] \"POST /solve HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['*', '4.0', '12.0']]\n",
      "( x  ) (  4.0 * 12.0 )\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from flask import Flask, Response, request\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def hello():\n",
    "    return \"Hello World!\"\n",
    "\n",
    "\n",
    "@app.route('/solve', methods=['GET', 'POST'])\n",
    "def eqn_solver_flask():\n",
    "    if request.method == 'POST':\n",
    "        print(request.json['question'])\n",
    "        list, eqn = get_ans_list(request.json['question'])\n",
    "        return {'list': list, 'eqn': eqn}\n",
    "        # return question\n",
    "    # print(ques)\n",
    "    return {'list': 'wrong format'}\n",
    "\n",
    "\n",
    "app.run(host='0.0.0.0', port=8000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_ans_list('the sum of 2 and a number is 1 . find the number .')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
